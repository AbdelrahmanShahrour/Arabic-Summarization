{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "s6wU7iENkDfO",
   "metadata": {
    "id": "s6wU7iENkDfO"
   },
   "source": [
    "# install `transformers`, `datasets`, `git-lfs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NhlYBUeVGLKP",
   "metadata": {
    "id": "NhlYBUeVGLKP"
   },
   "outputs": [],
   "source": [
    "!pip install transformers[sentencepiece]\n",
    "!pip install datasets\n",
    "!apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dUW4uWDkW4l",
   "metadata": {
    "id": "3dUW4uWDkW4l"
   },
   "source": [
    "# login `huggingface`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jxKBP_HCmrax",
   "metadata": {
    "id": "jxKBP_HCmrax"
   },
   "outputs": [],
   "source": [
    "my_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DEUlHwo_GmYP",
   "metadata": {
    "id": "DEUlHwo_GmYP"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45jkBpCNkq8p",
   "metadata": {
    "id": "45jkBpCNkq8p"
   },
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230916db",
   "metadata": {
    "id": "230916db"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import (AutoTokenizer, \n",
    "                          PreTrainedTokenizer,\n",
    "                          AutoTokenizer,\n",
    "                          AutoModelForSeq2SeqLM,\n",
    "                          DataCollatorForSeq2Seq,\n",
    "                          Seq2SeqTrainingArguments,\n",
    "                          Seq2SeqTrainer\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "\n",
    "# model name\n",
    "AraBART = \"moussaKam/AraBART\"\n",
    "# dataset name\n",
    "data = \"csebuetnlp/xlsum\"\n",
    "# transformer version\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Yq0XZICJlbla",
   "metadata": {
    "id": "Yq0XZICJlbla"
   },
   "source": [
    "# load dataset from huggingface hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115b1427",
   "metadata": {
    "id": "115b1427"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset( data , \"arabic\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L9i9S-tGnJee",
   "metadata": {
    "id": "L9i9S-tGnJee"
   },
   "source": [
    "# load tokenizer for `AraBART` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce0e14",
   "metadata": {
    "id": "a4ce0e14"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained( AraBART )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf7b172",
   "metadata": {
    "id": "4cf7b172"
   },
   "outputs": [],
   "source": [
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523c508",
   "metadata": {
    "id": "3523c508"
   },
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocessing(rows):\n",
    "    inputs = [row for row in rows[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(rows[\"summary\"], max_length=max_target_length, truncation=True)\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1078b5",
   "metadata": {
    "id": "cd1078b5"
   },
   "outputs": [],
   "source": [
    "preprocessing(dataset[\"train\"][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057d7ca",
   "metadata": {
    "id": "b057d7ca"
   },
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(preprocessing, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be5b879",
   "metadata": {
    "id": "7be5b879"
   },
   "outputs": [],
   "source": [
    "traind_model = AutoModelForSeq2SeqLM.from_pretrained( AraBART )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af548a5",
   "metadata": {
    "id": "9af548a5"
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "arguments = Seq2SeqTrainingArguments(\n",
    "    \"AraBART-summ\",\n",
    "    evaluation_strategy = [\"epoch\", \"Rouge\"],\n",
    "    learning_rate = 5e-5,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    num_train_epochs=1,\n",
    "    push_to_hub=True,\n",
    "    push_to_hub_token = my_token,\n",
    "    predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8dd687",
   "metadata": {
    "id": "ef8dd687"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=traind_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8036a3",
   "metadata": {
    "id": "5a8036a3"
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    traind_model,\n",
    "    arguments,\n",
    "    train_dataset = tokenized_dataset[\"train\"],\n",
    "    eval_dataset = tokenized_dataset[\"validation\"],\n",
    "    data_collator = data_collator,\n",
    "    tokenizer = tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece5299",
   "metadata": {
    "id": "6ece5299"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6487ad",
   "metadata": {
    "id": "9f6487ad"
   },
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"AraBART-summ\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
