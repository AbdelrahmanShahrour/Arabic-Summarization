{"cells":[{"cell_type":"markdown","source":["# install `transformers`, `datasets`, `git-lfs`"],"metadata":{"id":"s6wU7iENkDfO"},"id":"s6wU7iENkDfO"},{"cell_type":"code","source":["!pip install transformers[sentencepiece]\n","!pip install datasets\n","!apt-get install git-lfs"],"metadata":{"id":"NhlYBUeVGLKP"},"id":"NhlYBUeVGLKP","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# login `huggingface`"],"metadata":{"id":"3dUW4uWDkW4l"},"id":"3dUW4uWDkW4l"},{"cell_type":"code","source":["my_token = \"\""],"metadata":{"id":"jxKBP_HCmrax"},"id":"jxKBP_HCmrax","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from huggingface_hub import login\n","login()"],"metadata":{"id":"DEUlHwo_GmYP"},"id":"DEUlHwo_GmYP","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# import"],"metadata":{"id":"45jkBpCNkq8p"},"id":"45jkBpCNkq8p"},{"cell_type":"code","execution_count":null,"id":"230916db","metadata":{"id":"230916db"},"outputs":[],"source":["import transformers\n","from transformers import (AutoTokenizer, \n","                          PreTrainedTokenizer,\n","                          AutoTokenizer,\n","                          AutoModelForSeq2SeqLM,\n","                          DataCollatorForSeq2Seq,\n","                          Seq2SeqTrainingArguments,\n","                          Seq2SeqTrainer\n",")\n","from datasets import load_dataset\n","\n","from tokenizers import Tokenizer\n","\n","\n","# model name\n","AraBART = \"moussaKam/AraBART\"\n","# dataset name\n","data = \"csebuetnlp/xlsum\"\n","# transformer version\n","transformers.__version__"]},{"cell_type":"markdown","source":["# load dataset from huggingface hub"],"metadata":{"id":"Yq0XZICJlbla"},"id":"Yq0XZICJlbla"},{"cell_type":"code","execution_count":null,"id":"115b1427","metadata":{"id":"115b1427"},"outputs":[],"source":["dataset = load_dataset( data , \"arabic\")\n","dataset"]},{"cell_type":"markdown","source":["# load tokenizer for `AraBART` model"],"metadata":{"id":"L9i9S-tGnJee"},"id":"L9i9S-tGnJee"},{"cell_type":"code","execution_count":null,"id":"a4ce0e14","metadata":{"id":"a4ce0e14"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained( AraBART )"]},{"cell_type":"code","execution_count":null,"id":"4cf7b172","metadata":{"id":"4cf7b172"},"outputs":[],"source":["dataset['train'][1]"]},{"cell_type":"code","execution_count":null,"id":"3523c508","metadata":{"id":"3523c508"},"outputs":[],"source":["max_input_length = 1024\n","max_target_length = 128\n","\n","def preprocessing(rows):\n","    inputs = [row for row in rows[\"text\"]]\n","    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","    \n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(rows[\"summary\"], max_length=max_target_length, truncation=True)\n","    \n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs"]},{"cell_type":"code","execution_count":null,"id":"cd1078b5","metadata":{"id":"cd1078b5"},"outputs":[],"source":["preprocessing(dataset[\"train\"][:1])"]},{"cell_type":"code","execution_count":null,"id":"b057d7ca","metadata":{"id":"b057d7ca"},"outputs":[],"source":["tokenized_dataset = dataset.map(preprocessing, batched=True)"]},{"cell_type":"code","execution_count":null,"id":"7be5b879","metadata":{"id":"7be5b879"},"outputs":[],"source":["traind_model = AutoModelForSeq2SeqLM.from_pretrained( AraBART )"]},{"cell_type":"code","execution_count":null,"id":"9af548a5","metadata":{"id":"9af548a5"},"outputs":[],"source":["batch_size = 4\n","arguments = Seq2SeqTrainingArguments(\n","    \"AraBART-summ\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate = 5e-5,\n","    per_device_train_batch_size = batch_size,\n","    per_device_eval_batch_size = batch_size,\n","    num_train_epochs=1,\n","    push_to_hub=True,\n","    push_to_hub_token = my_token,\n","    predict_with_generate=True,\n",")"]},{"cell_type":"code","execution_count":null,"id":"ef8dd687","metadata":{"id":"ef8dd687"},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=traind_model)"]},{"cell_type":"code","execution_count":null,"id":"5a8036a3","metadata":{"id":"5a8036a3"},"outputs":[],"source":["trainer = Seq2SeqTrainer(\n","    traind_model,\n","    arguments,\n","    train_dataset = tokenized_dataset[\"train\"],\n","    eval_dataset = tokenized_dataset[\"validation\"],\n","    data_collator = data_collator,\n","    tokenizer = tokenizer,\n",")"]},{"cell_type":"code","execution_count":null,"id":"6ece5299","metadata":{"id":"6ece5299"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"id":"9f6487ad","metadata":{"id":"9f6487ad"},"outputs":[],"source":["trainer.push_to_hub(\"AraBART-summ\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm"},"accelerator":"GPU","gpuClass":"premium"},"nbformat":4,"nbformat_minor":5}