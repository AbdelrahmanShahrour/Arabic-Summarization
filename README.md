# Arabic Text Summarization

# 1 - Automatic text summarization
### 1.1 - Introduction
Over the beyond decades, the want to summarize files has routinely been regarded to boom because of the big mass of online texts consisting of news, scholarly articles, and so on. Assigning the summarization mission to a gadget has come to be a pressing want to extract and generate key statistics from the massive quantity of textual content available. Text summarization has been a place of excessive study for the beyond 50 years, specifically for generally used languages and comparatively easy grammar consisting of English. However, the Arabic language did now no longer get hold of an awful lot of interest because of its complexity grammatically and morphologically, etc. Arabic gives researchers and builders of the Natural Language Process (NLP) program enormous demanding situations because of its difficulties.

It is important to assess the effectiveness of the summaries generated via way of means of the gadget to decide the quantity of its reliability. There are methods, both human evaluation, that is, guide evaluation, which isn't a sensible approach withinside the case of big facts sets, or routinely the usage of the ROUGE metric, which is the only one that we undertake in this study.

## 1.2 - NLP
### 1.2.1 - Problem definition
### 1.2.2 - Application of NLP

## 1.3 - Arabic language and its challenges
### 1.3.1 - Arabic language
### 1.3.2 - Arabic encoding
### 1.3.3 - Arabic language challenges

## 1.4 - Text Summarization
### 1.4.1 - Manual summarization
### 1.4.2 - Automatic summarization
### 1.4.2.1 - Automatic text summarization aspects
### 1.4.2.2 - Automatic text summarization approaches
#### 1.4.2.2.1 - Extractive summarization
#### 1.4.2.2.2 - Abstractive summarization

## 1.5 - Related works
### 1.5.1 - Before the emergence of BERT
### 1.5.1 - Usage of BERT after its emergence

## 1.6 - Evaluation of summaries
## 1.7 - Conclusion

---
---
# 2 - Word embedding for text summarization
## 2.1 - Introduction
## 2.2 - Word embedding
### 2.2.1 - Traditional Word Embedding
### 2.2.2 - Static Word Embedding
### 2.2.3 - Contextualized Word Embedding
## 2.3 - Word embedding based on deep learning
### 2.3.1 - Artificial Neural Network (ANN)
### 2.3.2 - Deep Networks
### 2.3.3 - Sequence-to-sequence models
### 2.3.4 - Attention mechanism
### 2.3.5 - Transformers
### 2.3.6 - BERT
### 2.3.7 - BART
### 2.3.8 - PEGASUS
## 2.4 - Conclusion
---
---
# 3 - System design
## 3.1 - Introduction
## 3.2 - Arabic text preprocessing
## 3.3 - Text summarizer based on BART
### 3.3.1 - Model construction
### 3.3.1 - Prediction phase
## 3.4 - Text summarizer based on PEGASUS
## 3.5 - Conclusion
---
---
# 4 - Implementation and results
